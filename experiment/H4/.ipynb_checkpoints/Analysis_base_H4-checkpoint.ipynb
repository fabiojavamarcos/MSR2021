{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#https://altair-viz.github.io/gallery/errorbars_with_std.html\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "#defining paths\n",
    "allAlgorithms_unigram_900terms = './boxplotH4.csv'\n",
    "#classifierChain = './experiment/dfTesteClassifierChain_13Labels.csv'\n",
    "\n",
    "\n",
    "dataBinary = pd.read_csv(allAlgorithms_unigram_900terms)\n",
    "#dataClassifier = pd.read_csv(classifierChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>tf-IDF</th>\n",
       "      <th>#_TopTerms</th>\n",
       "      <th>Stop_Word</th>\n",
       "      <th>Train/Test_Size</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>Accuracy_Score_not_normalized</th>\n",
       "      <th>zero_one_loss</th>\n",
       "      <th>AUC-PR</th>\n",
       "      <th>hamming_loss_avg</th>\n",
       "      <th>Jaccard_samples</th>\n",
       "      <th>Jaccard_macro</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Fmeasure_Score</th>\n",
       "      <th>i</th>\n",
       "      <th>Hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>58:36.4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>20</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.733232</td>\n",
       "      <td>0.167254</td>\n",
       "      <td>0.508437</td>\n",
       "      <td>0.495575</td>\n",
       "      <td>0.696517</td>\n",
       "      <td>0.632054</td>\n",
       "      <td>0.662722</td>\n",
       "      <td>0</td>\n",
       "      <td>H4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>58:37.7</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>14</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.183685</td>\n",
       "      <td>0.455494</td>\n",
       "      <td>0.454704</td>\n",
       "      <td>0.641278</td>\n",
       "      <td>0.609813</td>\n",
       "      <td>0.625150</td>\n",
       "      <td>1</td>\n",
       "      <td>H4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>58:39.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>12</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.657553</td>\n",
       "      <td>0.184272</td>\n",
       "      <td>0.456534</td>\n",
       "      <td>0.449123</td>\n",
       "      <td>0.628993</td>\n",
       "      <td>0.610979</td>\n",
       "      <td>0.619855</td>\n",
       "      <td>2</td>\n",
       "      <td>H4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>58:40.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.119718</td>\n",
       "      <td>17</td>\n",
       "      <td>0.880282</td>\n",
       "      <td>0.672158</td>\n",
       "      <td>0.178404</td>\n",
       "      <td>0.474729</td>\n",
       "      <td>0.471304</td>\n",
       "      <td>0.660976</td>\n",
       "      <td>0.621560</td>\n",
       "      <td>0.640662</td>\n",
       "      <td>3</td>\n",
       "      <td>H4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>58:42.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>20</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.702048</td>\n",
       "      <td>0.166080</td>\n",
       "      <td>0.504209</td>\n",
       "      <td>0.498227</td>\n",
       "      <td>0.709596</td>\n",
       "      <td>0.625835</td>\n",
       "      <td>0.665089</td>\n",
       "      <td>4</td>\n",
       "      <td>H4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>58:43.3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.161972</td>\n",
       "      <td>23</td>\n",
       "      <td>0.838028</td>\n",
       "      <td>0.695836</td>\n",
       "      <td>0.163146</td>\n",
       "      <td>0.514009</td>\n",
       "      <td>0.497288</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.635104</td>\n",
       "      <td>0.664251</td>\n",
       "      <td>5</td>\n",
       "      <td>H4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>58:44.7</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>14</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.685139</td>\n",
       "      <td>0.176056</td>\n",
       "      <td>0.489493</td>\n",
       "      <td>0.477352</td>\n",
       "      <td>0.697201</td>\n",
       "      <td>0.602198</td>\n",
       "      <td>0.646226</td>\n",
       "      <td>6</td>\n",
       "      <td>H4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>58:46.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.126761</td>\n",
       "      <td>18</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.185446</td>\n",
       "      <td>0.449830</td>\n",
       "      <td>0.441696</td>\n",
       "      <td>0.621891</td>\n",
       "      <td>0.603865</td>\n",
       "      <td>0.612745</td>\n",
       "      <td>7</td>\n",
       "      <td>H4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>58:47.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.126761</td>\n",
       "      <td>18</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.665636</td>\n",
       "      <td>0.165493</td>\n",
       "      <td>0.487156</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0.665835</td>\n",
       "      <td>0.643373</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>8</td>\n",
       "      <td>H4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>58:48.8</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.119718</td>\n",
       "      <td>17</td>\n",
       "      <td>0.880282</td>\n",
       "      <td>0.648353</td>\n",
       "      <td>0.167254</td>\n",
       "      <td>0.465543</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.636943</td>\n",
       "      <td>9</td>\n",
       "      <td>H4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>58:19.9</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>900</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.161972</td>\n",
       "      <td>23</td>\n",
       "      <td>0.838028</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.165493</td>\n",
       "      <td>0.517684</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.699752</td>\n",
       "      <td>0.636569</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>58:21.2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>900</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>13</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.654757</td>\n",
       "      <td>0.183099</td>\n",
       "      <td>0.457070</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>1</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>58:22.6</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>900</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>13</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.660442</td>\n",
       "      <td>0.183685</td>\n",
       "      <td>0.465118</td>\n",
       "      <td>0.456597</td>\n",
       "      <td>0.626190</td>\n",
       "      <td>0.627685</td>\n",
       "      <td>0.626937</td>\n",
       "      <td>2</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>58:24.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>900</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>16</td>\n",
       "      <td>0.887324</td>\n",
       "      <td>0.669685</td>\n",
       "      <td>0.181925</td>\n",
       "      <td>0.468195</td>\n",
       "      <td>0.464594</td>\n",
       "      <td>0.652913</td>\n",
       "      <td>0.616972</td>\n",
       "      <td>0.634434</td>\n",
       "      <td>3</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>58:25.3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>900</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>22</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.708615</td>\n",
       "      <td>0.164906</td>\n",
       "      <td>0.513400</td>\n",
       "      <td>0.501773</td>\n",
       "      <td>0.711055</td>\n",
       "      <td>0.630290</td>\n",
       "      <td>0.668241</td>\n",
       "      <td>4</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>58:26.7</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>900</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.133803</td>\n",
       "      <td>19</td>\n",
       "      <td>0.866197</td>\n",
       "      <td>0.692722</td>\n",
       "      <td>0.167840</td>\n",
       "      <td>0.499444</td>\n",
       "      <td>0.489286</td>\n",
       "      <td>0.683292</td>\n",
       "      <td>0.632794</td>\n",
       "      <td>0.657074</td>\n",
       "      <td>5</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>58:28.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>900</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>15</td>\n",
       "      <td>0.894366</td>\n",
       "      <td>0.688532</td>\n",
       "      <td>0.176643</td>\n",
       "      <td>0.489873</td>\n",
       "      <td>0.478336</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.606593</td>\n",
       "      <td>0.647128</td>\n",
       "      <td>6</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>58:29.4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>900</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>15</td>\n",
       "      <td>0.894366</td>\n",
       "      <td>0.620070</td>\n",
       "      <td>0.186033</td>\n",
       "      <td>0.450808</td>\n",
       "      <td>0.446771</td>\n",
       "      <td>0.616867</td>\n",
       "      <td>0.618357</td>\n",
       "      <td>0.617612</td>\n",
       "      <td>7</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>58:30.9</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>900</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>15</td>\n",
       "      <td>0.894366</td>\n",
       "      <td>0.667117</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>0.472720</td>\n",
       "      <td>0.479204</td>\n",
       "      <td>0.657568</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.647922</td>\n",
       "      <td>8</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>58:32.2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>900</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>16</td>\n",
       "      <td>0.887324</td>\n",
       "      <td>0.634557</td>\n",
       "      <td>0.167840</td>\n",
       "      <td>0.466080</td>\n",
       "      <td>0.465421</td>\n",
       "      <td>0.616337</td>\n",
       "      <td>0.655263</td>\n",
       "      <td>0.635204</td>\n",
       "      <td>9</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_time  tf-IDF  #_TopTerms Stop_Word  Train/Test_Size     Algorithm  \\\n",
       "0    58:36.4  (1, 1)         745       Yes              0.2  RandomForest   \n",
       "1    58:37.7  (1, 1)         745       Yes              0.2  RandomForest   \n",
       "2    58:39.0  (1, 1)         745       Yes              0.2  RandomForest   \n",
       "3    58:40.5  (1, 1)         745       Yes              0.2  RandomForest   \n",
       "4    58:42.0  (1, 1)         745       Yes              0.2  RandomForest   \n",
       "5    58:43.3  (1, 1)         745       Yes              0.2  RandomForest   \n",
       "6    58:44.7  (1, 1)         745       Yes              0.2  RandomForest   \n",
       "7    58:46.0  (1, 1)         745       Yes              0.2  RandomForest   \n",
       "8    58:47.5  (1, 1)         745       Yes              0.2  RandomForest   \n",
       "9    58:48.8  (1, 1)         745       Yes              0.2  RandomForest   \n",
       "10   58:19.9  (1, 1)         900       Yes              0.2  RandomForest   \n",
       "11   58:21.2  (1, 1)         900       Yes              0.2  RandomForest   \n",
       "12   58:22.6  (1, 1)         900       Yes              0.2  RandomForest   \n",
       "13   58:24.0  (1, 1)         900       Yes              0.2  RandomForest   \n",
       "14   58:25.3  (1, 1)         900       Yes              0.2  RandomForest   \n",
       "15   58:26.7  (1, 1)         900       Yes              0.2  RandomForest   \n",
       "16   58:28.1  (1, 1)         900       Yes              0.2  RandomForest   \n",
       "17   58:29.4  (1, 1)         900       Yes              0.2  RandomForest   \n",
       "18   58:30.9  (1, 1)         900       Yes              0.2  RandomForest   \n",
       "19   58:32.2  (1, 1)         900       Yes              0.2  RandomForest   \n",
       "\n",
       "    Accuracy_Score  Accuracy_Score_not_normalized  zero_one_loss    AUC-PR  \\\n",
       "0         0.140845                             20       0.859155  0.733232   \n",
       "1         0.098592                             14       0.901408  0.655000   \n",
       "2         0.084507                             12       0.915493  0.657553   \n",
       "3         0.119718                             17       0.880282  0.672158   \n",
       "4         0.140845                             20       0.859155  0.702048   \n",
       "5         0.161972                             23       0.838028  0.695836   \n",
       "6         0.098592                             14       0.901408  0.685139   \n",
       "7         0.126761                             18       0.873239  0.617566   \n",
       "8         0.126761                             18       0.873239  0.665636   \n",
       "9         0.119718                             17       0.880282  0.648353   \n",
       "10        0.161972                             23       0.838028  0.726639   \n",
       "11        0.091549                             13       0.908451  0.654757   \n",
       "12        0.091549                             13       0.908451  0.660442   \n",
       "13        0.112676                             16       0.887324  0.669685   \n",
       "14        0.154930                             22       0.845070  0.708615   \n",
       "15        0.133803                             19       0.866197  0.692722   \n",
       "16        0.105634                             15       0.894366  0.688532   \n",
       "17        0.105634                             15       0.894366  0.620070   \n",
       "18        0.105634                             15       0.894366  0.667117   \n",
       "19        0.112676                             16       0.887324  0.634557   \n",
       "\n",
       "    hamming_loss_avg  Jaccard_samples  Jaccard_macro  Precision    Recall  \\\n",
       "0           0.167254         0.508437       0.495575   0.696517  0.632054   \n",
       "1           0.183685         0.455494       0.454704   0.641278  0.609813   \n",
       "2           0.184272         0.456534       0.449123   0.628993  0.610979   \n",
       "3           0.178404         0.474729       0.471304   0.660976  0.621560   \n",
       "4           0.166080         0.504209       0.498227   0.709596  0.625835   \n",
       "5           0.163146         0.514009       0.497288   0.696203  0.635104   \n",
       "6           0.176056         0.489493       0.477352   0.697201  0.602198   \n",
       "7           0.185446         0.449830       0.441696   0.621891  0.603865   \n",
       "8           0.165493         0.487156       0.486339   0.665835  0.643373   \n",
       "9           0.167254         0.465543       0.467290   0.617284  0.657895   \n",
       "10          0.165493         0.517684       0.500000   0.699752  0.636569   \n",
       "11          0.183099         0.457070       0.450704   0.646465  0.598131   \n",
       "12          0.183685         0.465118       0.456597   0.626190  0.627685   \n",
       "13          0.181925         0.468195       0.464594   0.652913  0.616972   \n",
       "14          0.164906         0.513400       0.501773   0.711055  0.630290   \n",
       "15          0.167840         0.499444       0.489286   0.683292  0.632794   \n",
       "16          0.176643         0.489873       0.478336   0.693467  0.606593   \n",
       "17          0.186033         0.450808       0.446771   0.616867  0.618357   \n",
       "18          0.169014         0.472720       0.479204   0.657568  0.638554   \n",
       "19          0.167840         0.466080       0.465421   0.616337  0.655263   \n",
       "\n",
       "    Fmeasure_Score  i Hypothesis  \n",
       "0         0.662722  0         H4  \n",
       "1         0.625150  1         H4  \n",
       "2         0.619855  2         H4  \n",
       "3         0.640662  3         H4  \n",
       "4         0.665089  4         H4  \n",
       "5         0.664251  5         H4  \n",
       "6         0.646226  6         H4  \n",
       "7         0.612745  7         H4  \n",
       "8         0.654412  8         H4  \n",
       "9         0.636943  9         H4  \n",
       "10        0.666667  0   Baseline  \n",
       "11        0.621359  1   Baseline  \n",
       "12        0.626937  2   Baseline  \n",
       "13        0.634434  3   Baseline  \n",
       "14        0.668241  4   Baseline  \n",
       "15        0.657074  5   Baseline  \n",
       "16        0.647128  6   Baseline  \n",
       "17        0.617612  7   Baseline  \n",
       "18        0.647922  8   Baseline  \n",
       "19        0.635204  9   Baseline  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'Algorithm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f4e46cbefe85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Algorithm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Evaluation Metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performance\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation Metrics by Hypothesis\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mboxplot\u001b[0;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth, whis, notch, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2229\u001b[0m     plotter = _BoxPlotter(x, y, hue, data, order, hue_order,\n\u001b[1;32m   2230\u001b[0m                           \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2231\u001b[0;31m                           width, dodge, fliersize, linewidth)\n\u001b[0m\u001b[1;32m   2232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth)\u001b[0m\n\u001b[1;32m    444\u001b[0m                  width, dodge, fliersize, linewidth):\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not interpret input '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;31m# Figure out the plotting orientation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret input 'Algorithm'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd=pd.melt(dataBinary,id_vars=['Hypothesis'],value_vars=['Precision','Recall','Fmeasure_Score'],var_name='Evaluation Metrics')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.boxplot(y='value',x='Algorithm',data=dd,hue='Evaluation Metrics')\n",
    "plt.ylabel(\"Performance\", size=12)\n",
    "plt.xlabel(\"Evaluation Metrics by Hypothesis\",size=12)\n",
    "\n",
    "labels=[\"Precision\", \"Recall\", \"F-measure\"]\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h, labels, title=\"Evaluation Metrics\",bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"Evaluation Metrics by Hypothesis\", size=12)\n",
    "plt.show()\n",
    "#plt.savefig(\"grouped_boxplot_AlgorithmBinary.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBinary.groupby(['tf-IDF','#_TopTerms','Algorithm']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBinary.nlargest(5,['Precision','Fmeasure_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.boxplot(y='AUC-PR',x='Algorithm',data=dataBinary)\n",
    "plt.ylabel(\"AUCpr distribution\", size=12)\n",
    "plt.xlabel(\"Hypothesis\",size=12)\n",
    "plt.title(\"Classifier Chain - AUCpr Analysis\", size=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.boxplot(y='hamming_loss_avg',x='Algorithm',data=dataBinary)\n",
    "plt.ylabel(\"Hamming Loss Average distribution\", size=12)\n",
    "plt.xlabel(\"Hypothesis\",size=12)\n",
    "plt.title(\"Classifier Chain - Hamming Loss Analysis\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.boxplot(y='Accuracy_Score_not_normalized',x='Algorithm',data=dataBinary)\n",
    "plt.ylabel(\"PR's correctly predicted\", size=12)\n",
    "plt.xlabel(\"Algorithms\",size=12)\n",
    "plt.title(\"Classifier Chain - Number of PR correctly predict considering all APIs\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cliffsDelta(lst1, lst2, **dull):\n",
    "\n",
    "    \"\"\"Returns delta and true if there are more than 'dull' differences\"\"\"\n",
    "    if not dull:\n",
    "        dull = {'small': 0.147, 'medium': 0.33, 'large': 0.474} # effect sizes from (Hess and Kromrey, 2004)\n",
    "    m, n = len(lst1), len(lst2)\n",
    "    lst2 = sorted(lst2)\n",
    "    j = more = less = 0\n",
    "    for repeats, x in runs(sorted(lst1)):\n",
    "        while j <= (n - 1) and lst2[j] < x:\n",
    "            j += 1\n",
    "        more += j*repeats\n",
    "        while j <= (n - 1) and lst2[j] == x:\n",
    "            j += 1\n",
    "        less += (n - j)*repeats\n",
    "    d = (more - less) / (m*n)\n",
    "    size = lookup_size(d, dull)\n",
    "    return d, size\n",
    "\n",
    "\n",
    "def lookup_size(delta: float, dull: dict) -> str:\n",
    "    \"\"\"\n",
    "    :type delta: float\n",
    "    :type dull: dict, a dictionary of small, medium, large thresholds.\n",
    "    \"\"\"\n",
    "    delta = abs(delta)\n",
    "    if delta < dull['small']:\n",
    "        return 'negligible'\n",
    "    if dull['small'] <= delta < dull['medium']:\n",
    "        return 'small'\n",
    "    if dull['medium'] <= delta < dull['large']:\n",
    "        return 'medium'\n",
    "    if delta >= dull['large']:\n",
    "        return 'large'\n",
    "\n",
    "\n",
    "def runs(lst):\n",
    "    \"\"\"Iterator, chunks repeated values\"\"\"\n",
    "    for j, two in enumerate(lst):\n",
    "        if j == 0:\n",
    "            one, i = two, 0\n",
    "        if one != two:\n",
    "            yield j - i, one\n",
    "            i = j\n",
    "        one = two\n",
    "    yield j - i + 1, two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/effect-size-measures-in-python/\n",
    "#Small Effect Size: d=0.20\n",
    "#Medium Effect Size: d=0.50\n",
    "#Large Effect Size: d=0.80\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import var\n",
    "from math import sqrt\n",
    "\n",
    "def cohend(d1, d2):\n",
    "\t# calculate the size of samples\n",
    "\tn1, n2 = len(d1), len(d2)\n",
    "\t# calculate the variance of the samples\n",
    "\ts1, s2 = var(d1, ddof=1), var(d2, ddof=1)\n",
    "\t# calculate the pooled standard deviation\n",
    "\ts = sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "\t# calculate the means of the samples\n",
    "\tu1, u2 = mean(d1), mean(d2)\n",
    "\t# calculate the effect size\n",
    "\treturn (u1 - u2) / s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting data to compute Stats\n",
    "\n",
    "RF_binary = dataBinary[dataBinary.Algorithm == 'RandomForest']\n",
    "RF_FMeasure = RF_binary['Fmeasure_Score']\n",
    "\n",
    "LogisticRegression_binary = dataBinary[dataBinary.Algorithm == 'LogisticRegression']\n",
    "LogisticRegression_FMeasure = LogisticRegression_binary['Fmeasure_Score']\n",
    "\n",
    "MLPC_binary = dataBinary[dataBinary.Algorithm == 'MLPClassifier']\n",
    "MLPC_FMeasure = MLPC_binary['Fmeasure_Score']\n",
    "\n",
    "DT_binary = dataBinary[dataBinary.Algorithm == 'DecisionTree']\n",
    "DT_FMeasure = DT_binary['Fmeasure_Score']\n",
    "\n",
    "MlkNN_binary = dataBinary[dataBinary.Algorithm == 'MLkNN']\n",
    "MlkNN_FMeasure = MlkNN_binary['Fmeasure_Score']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Kruskall Wallis - Group Comparison\n",
    "\n",
    "#Fail to Reject H0: Paired sample distributions are equal.\n",
    "#Reject H0: Paired sample distributions are not equal.\n",
    "    \n",
    "from scipy.stats import kruskal\n",
    "# seed the random number generator\n",
    "\n",
    "\n",
    "# compare samples\n",
    "stat, p = kruskal(RF_FMeasure,LogisticRegression_FMeasure, MLPC_FMeasure,DT_FMeasure,MlkNN_FMeasure)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# compare samples\n",
    "stat, p = friedmanchisquare(RF_FMeasure,LogisticRegression_FMeasure,MLPC_FMeasure,DT_FMeasure,MlkNN_FMeasure)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distributions (reject H0)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MANN-U Independent Samples\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "#Fail to Reject H0: Sample distributions are equal.\n",
    "#Reject H0: Sample distributions are not equal.\n",
    "\n",
    "##### Defining variables to be comparede\n",
    "\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(RF_FMeasure, LogisticRegression_FMeasure)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distribution (reject H0)')\n",
    "\n",
    "   \n",
    "#Effect_Size RandomForest Vs others   \n",
    "print(cliffsDelta(RF_FMeasure, LogisticRegression_FMeasure))\n",
    "print(cliffsDelta(RF_FMeasure, MLPC_FMeasure))\n",
    "print(cliffsDelta(RF_FMeasure, DT_FMeasure))\n",
    "print(cliffsDelta(RF_FMeasure, MlkNN_FMeasure)) #divisionByZero error\n",
    "\n",
    "#Effect_Size LogisticRegression Vs others\n",
    "print(cliffsDelta(LogisticRegression_FMeasure, MLPC_FMeasure))\n",
    "print(cliffsDelta(LogisticRegression_FMeasure, DT_FMeasure))\n",
    "print(cliffsDelta(LogisticRegression_FMeasure, MlkNN_FMeasure))\n",
    "\n",
    "#Effect_Size MLPC Vs others\n",
    "print(cliffsDelta(MLPC_FMeasure, DT_FMeasure))\n",
    "print(cliffsDelta(MLPC_FMeasure, MlkNN_FMeasure))\n",
    "\n",
    "#Effect_Size MlkNN Vs others\n",
    "print(cliffsDelta(MlkNN_FMeasure,DT_FMeasure))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Effect_Size RandomForest Vs others   \n",
    "print('Cohens d: %.3f' % cohend(RF_FMeasure, LogisticRegression_FMeasure))    \n",
    "print('Cohens d: %.3f' % cohend(RF_FMeasure, MLPC_FMeasure))\n",
    "print('Cohens d: %.3f' % cohend(RF_FMeasure, DT_FMeasure))\n",
    "print('Cohens d: %.3f' % cohend(RF_FMeasure, MlkNN_FMeasure))\n",
    "\n",
    "#Effect_Size LogisticRegression Vs others\n",
    "print('Cohens d: %.3f' % cohend(LogisticRegression_FMeasure, MLPC_FMeasure))    \n",
    "print('Cohens d: %.3f' % cohend(LogisticRegression_FMeasure, DT_FMeasure))    \n",
    "print('Cohens d: %.3f' % cohend(LogisticRegression_FMeasure, MlkNN_FMeasure))    \n",
    "\n",
    "#Effect_Size MLPC Vs others\n",
    "print('Cohens d: %.3f' % cohend(MLPC_FMeasure, DT_FMeasure))    \n",
    "print('Cohens d: %.3f' % cohend(MLPC_FMeasure, MlkNN_FMeasure))    \n",
    "\n",
    "#Effect_Size MlkNN Vs others\n",
    "print('Cohens d: %.3f' % cohend(MlkNN_FMeasure,DT_FMeasure))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Wilcoxon paired and dependent samples\n",
    "\n",
    "#Fail to Reject H0: Sample distributions are equal.\n",
    "#Reject H0: Sample distributions are not equal.\n",
    "\n",
    "#from scipy.stats import wilcoxon\n",
    "\n",
    "#stat, p = wilcoxon(data1, data2)\n",
    "#print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "#alpha = 0.05\n",
    "#if p > alpha:\n",
    "#\tprint('Same distribution (fail to reject H0)')\n",
    "#else:\n",
    "#\tprint('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Precision analysis\n",
    "#Subsetting data to compute Stats\n",
    "\n",
    "RF_binary = dataBinary[dataBinary.Algorithm == 'RandomForest']\n",
    "RF_Precision = RF_binary['Precision']\n",
    "\n",
    "LogisticRegression_binary = dataBinary[dataBinary.Algorithm == 'LogisticRegression']\n",
    "LogisticRegression_Precision = LogisticRegression_binary['Precision']\n",
    "\n",
    "MLPC_binary = dataBinary[dataBinary.Algorithm == 'MLPClassifier']\n",
    "MLPC_Precision = MLPC_binary['Precision']\n",
    "\n",
    "DT_binary = dataBinary[dataBinary.Algorithm == 'DecisionTree']\n",
    "DT_Precision = DT_binary['Precision']\n",
    "\n",
    "MlkNN_binary = dataBinary[dataBinary.Algorithm == 'MLkNN']\n",
    "MlkNN_Precision = MlkNN_binary['Precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MANN-U Independent Samples\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "#Fail to Reject H0: Sample distributions are equal.\n",
    "#Reject H0: Sample distributions are not equal.\n",
    "\n",
    "##### Defining variables to be comparede\n",
    "\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(RF_FMeasure, LogisticRegression_FMeasure)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distribution (reject H0)')\n",
    "\n",
    "   \n",
    "#Effect_Size RandomForest Vs others   \n",
    "print(cliffsDelta(RF_Precision, LogisticRegression_Precision))\n",
    "print(cliffsDelta(RF_Precision, MLPC_Precision))\n",
    "print(cliffsDelta(RF_Precision, DT_Precision))\n",
    "print(cliffsDelta(RF_Precision, MlkNN_Precision)) #divisionByZero error\n",
    "\n",
    "#Effect_Size LogisticRegression Vs others\n",
    "print(cliffsDelta(LogisticRegression_Precision, MLPC_Precision))\n",
    "print(cliffsDelta(LogisticRegression_Precision, DT_Precision))\n",
    "print(cliffsDelta(LogisticRegression_Precision, MlkNN_Precision))\n",
    "\n",
    "#Effect_Size MLPC Vs others\n",
    "print(cliffsDelta(MLPC_Precision, DT_Precision))\n",
    "print(cliffsDelta(MLPC_Precision, MlkNN_Precision))\n",
    "\n",
    "#Effect_Size MlkNN Vs others\n",
    "print(cliffsDelta(MlkNN_Precision,DT_Precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Kruskall Wallis - Group Comparison\n",
    "\n",
    "#Fail to Reject H0: Paired sample distributions are equal.\n",
    "#Reject H0: Paired sample distributions are not equal.\n",
    "    \n",
    "from scipy.stats import kruskal\n",
    "# seed the random number generator\n",
    "\n",
    "\n",
    "# compare samples\n",
    "stat, p = kruskal(RF_Precision,LogisticRegression_Precision, MLPC_Precision,DT_Precision,MlkNN_Precision)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# compare samples\n",
    "stat, p = friedmanchisquare(RF_Precision,LogisticRegression_Precision, MLPC_Precision,DT_Precision,MlkNN_Precision)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
